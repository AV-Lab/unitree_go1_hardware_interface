# ğŸ§  Sagittarius K1 Arm - Perception Stack

This repository contains the full perception + grasping stack for the **Sagittarius K1 robotic arm**, including:

- RealSense camera drivers
- Object detection based on color
- Motion planning via MoveIt
- Gripper control and pick-return routine

---

## ğŸ“ Repository Structure

```
perception_stack/
â”œâ”€â”€ docker-compose.yml             # (Optional) Template to set up container
â”œâ”€â”€ sagittarius_control/          # ğŸ”§ Custom ROS package for perception + grasping
â”‚   â”œâ”€â”€ config/                   # YAML files for HSV ranges and pre/post pick poses
â”‚   â”œâ”€â”€ launch/                   # Launch files for detection, pre-pick, and motion logic
â”‚   â”œâ”€â”€ nodes/                    # Python scripts: detector, move logic, etc.
â”‚   â””â”€â”€ src/                      # Optional C++ nodes (e.g., RViz joint mirror)
â”œâ”€â”€ sagittarius_descriptions/     # ğŸ¤– URDF and robot description files
â”œâ”€â”€ sagittarius_moveit/           # ğŸ§  MoveIt motion planning setup
â”œâ”€â”€ sdk_sagittarius_arm/          # ğŸ§© Vendor-provided driver package
â”œâ”€â”€ realsense-ros/                # ğŸ¥ RealSense D435 camera drivers
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Prerequisites

- **Ubuntu 20.04** (recommended)
- **ROS Noetic**
- Python 3.8+
- RealSense D435 camera
- Sagittarius K1 robotic arm

If you want to containerize the stack, use this `docker-compose.yml` as a starting point.

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/AV-Lab/unitree_go1_hardware_interface.git
cd unitree_go1_hardware_interface/k1_arm/perception_stack
```

### 2. Build the Workspace

```bash
catkin_make
source devel/setup.bash
```

---

## ğŸš€ How to Run the Full Pipeline

### 1. Start the RealSense Camera and Object Detector:

```bash
roslaunch sagittarius_control detect_objects.launch color_name:=green
```

(Defaults to green if no color is passed)

### 2. Run the Main Pick Logic:

```bash
roslaunch sagittarius_control auto_pick_pipeline.launch
```

This will:

- Visualize detected object in RViz
- Move to the object
- Close the gripper
- Return to the configured **post-pick** pose

---

## âš™ï¸ Configuration Files

### `sagittarius_control/config/color_config.yaml`

HSV threshold ranges for each color (green, red, blue, etc.):

```yaml
green:
  lower: [40, 70, 70]
  upper: [80, 255, 255]
blue:
  lower: [100, 150, 0]
  upper: [140, 255, 255]
```

### `sagittarius_control/config/pre_pick_pose.yaml`

Specifies starting and final pose values:

```yaml
post_pick_rad: [0.0, 0.3, 0.0, 0.4, -1.8, 0.0]
```

---

## ğŸ“¸ Demos

(Include your demo GIFs, screenshots or videos here)

---

## ğŸ§  Credits

This stack integrates:

- ROS packages from the official NXROBO Sagittarius K1 SDK
- Intel RealSense camera drivers
