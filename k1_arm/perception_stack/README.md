# üß† Sagittarius K1 Arm - Perception Stack

This repository contains the full perception + grasping stack for the **Sagittarius K1 robotic arm**, including:

- RealSense camera drivers
- Object detection based on color
- Motion planning via MoveIt
- Gripper control and pick-return routine

---

## üìÅ Repository Structure

```
perception_stack/
‚îú‚îÄ‚îÄ docker-compose.yml             # (Optional) Template to set up container
‚îú‚îÄ‚îÄ sagittarius_control/          # üîß Custom ROS package for perception + grasping
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # YAML files for HSV ranges and pre/post pick poses
‚îÇ   ‚îú‚îÄ‚îÄ launch/                   # Launch files for detection, pre-pick, and motion logic
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                    # Python scripts: detector, move logic, etc.
‚îÇ   ‚îî‚îÄ‚îÄ src/                      # Optional C++ nodes (e.g., RViz joint mirror)
‚îú‚îÄ‚îÄ sagittarius_descriptions/     # ü§ñ URDF and robot description files
‚îú‚îÄ‚îÄ sagittarius_moveit/           # üß† MoveIt motion planning setup
‚îú‚îÄ‚îÄ sdk_sagittarius_arm/          # üß© Vendor-provided driver package
‚îú‚îÄ‚îÄ realsense-ros/                # üé• RealSense D435 camera drivers
‚îî‚îÄ‚îÄ README.md
```

---

## üõ†Ô∏è Prerequisites

- **Ubuntu 20.04** (recommended)
- **ROS Noetic**
- Python 3.8+
- RealSense D435 camera
- Sagittarius K1 robotic arm

> ‚úÖ Optional: Docker setup available (see below)

---

## üîß Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/AV-Lab/unitree_go1_hardware_interface.git
cd unitree_go1_hardware_interface/k1_arm/perception_stack
```

### 2. Build the Workspace

```bash
catkin_make
source devel/setup.bash
```

---

## üöÄ How to Run the Full Pipeline

### 1. Start the RealSense Camera and Object Detector:

```bash
roslaunch sagittarius_control detect_objects.launch color_name:=green
```

(Defaults to green if no color is passed)

### 2. Run the Main Pick Logic:

```bash
roslaunch sagittarius_control auto_pick_pipeline.launch
```

This will:

- Visualize detected object in RViz
- Move to the object
- Close the gripper
- Return to the configured **post-pick** pose

---

## ‚öôÔ∏è Configuration Files

### `sagittarius_control/config/color_config.yaml`

HSV threshold ranges for each color (green, red, blue, etc.):

```yaml
green:
  lower: [40, 70, 70]
  upper: [80, 255, 255]
blue:
  lower: [100, 150, 0]
  upper: [140, 255, 255]
```

### `sagittarius_control/config/pre_pick_pose.yaml`

Specifies starting and final pose values:

```yaml
post_pick_rad: [0.0, 0.3, 0.0, 0.4, -1.8, 0.0]
```

---

## üê≥ Docker (Optional Template)

If you want to containerize the stack, use this `docker-compose.yml` as a starting point:

```yaml
docker-compose.yml

services:
  ros:
    image: ros:noetic
    container_name: k1
    network_mode: host
    privileged: true
    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix
      - /etc/localtime:/etc/localtime:ro
      - /dev/:/dev/
      - /dev/bus/usb:/dev/bus/usb
      - /run/udev:/run/udev:ro
    environment:
      - color_prompt=yes
      - DISPLAY
      - TERM
      - QT_X11_NO_MITSHM=1
      - DRI_NAME=card1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - NV_PRIME_RENDER_OFFLOAD=1
      - GLX_VENDOR_LIBRARY_NAME=nvidia
    tty: true
    stdin_open: true
    devices:
      - /dev/:/dev/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
```

---

## üì∏ Demos

(Include your demo GIFs, screenshots or videos here)

---

## üß† Credits

This stack integrates:

- ROS packages from the official NXROBO Sagittarius K1 SDK
- Intel RealSense camera drivers
